{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81af6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# Instansiate the Plotly charting library.\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "# We use plotly.offline as this allows us to create interactive \n",
    "# visualisations without the use of an internet connection, \n",
    "# making our notebook more distributable to others. \n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# The Cufflinks library allows us to directly bind \n",
    "# Pandas dataframes to Plotly charts. \n",
    "import cufflinks as cf\n",
    "# Once again we use the Cufflinks library in offline mode. \n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(colorscale='plotly', world_readable=True)\n",
    "\n",
    "# Extra options. We use these to make our interactive \n",
    "# visualisations more aesthetically appealing. \n",
    "from IPython.core.display import HTML\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_columns = 25\n",
    "\n",
    "# Show all code cells outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from ipywidgets import interact, interact_manual, widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/freeman_well_4_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e864633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Facies_code'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd0f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Facies']= lab_enc.fit_transform(df['Facies_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Facies'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def correlations(column1=list(df.select_dtypes('number').columns), \n",
    "                 column2=list(df.select_dtypes('number').columns)):\n",
    "    print(f\"Correlation: {df[column1].corr(df[column2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def scatter_plot(x=list(df.select_dtypes('number').columns), \n",
    "                 y=list(df.select_dtypes('number').columns)[1:]):\n",
    "    if x == y:\n",
    "        print(f\"Please select seperate variables for X and Y\")\n",
    "    else:\n",
    "        df.iplot(kind='scatter', x=x, y=y, mode='markers', \n",
    "                 xTitle=x.title(), yTitle=y.title(), title=f'{y.title()} vs {x.title()}')\n",
    "        ## if you are using Google Colab, comment out the above line of code and uncomment the lines below\n",
    "        #fig = px.scatter(df, x=x, y=y, title=f'{y.title()} vs {x.title()}')\n",
    "        #fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ded5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cscales = ['Greys', 'YlGnBu', 'Greens', 'YlOrRd', 'Bluered', 'RdBu',\n",
    "            'Reds', 'Blues', 'Picnic', 'Rainbow', 'Portland', 'Jet',\n",
    "            'Hot', 'Blackbody', 'Earth', 'Electric', 'Viridis', 'Cividis']\n",
    "\n",
    "# We use the Figure Factory module of Plotly, which\n",
    "# defines many unique and powerful plots to be used\n",
    "# in Python. \n",
    "# For more info, see: https://plot.ly/python/figure-factory-subplots/\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "corrs = df.corr()\n",
    "\n",
    "@interact\n",
    "def plot_corrs(colorscale=cscales):\n",
    "    figure = ff.create_annotated_heatmap(z = corrs.round(2).values, \n",
    "                                     x =list(corrs.columns), \n",
    "                                     y=list(corrs.index), \n",
    "                                     colorscale=colorscale,\n",
    "                                     annotation_text=corrs.round(2).values)\n",
    "    iplot(figure)\n",
    "    ## if you are using Google Colab, comment out the above line of code and uncomment the line below\n",
    "    #figure.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b230e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def scatter_plot(x=list(df.select_dtypes('number').columns), \n",
    "                 y=list(df.select_dtypes('number').columns)[1:],\n",
    "                 theme=list(cf.themes.THEMES.keys()), \n",
    "                 colorscale=list(cf.colors._scales_names.keys())):\n",
    "    \n",
    "    if x == y:\n",
    "        print(f\"Please select seperate variables for X and Y\")\n",
    "    else:\n",
    "        df.iplot(kind='scatter', x=x, y=y, mode='markers', \n",
    "                 xTitle=x.title(), yTitle=y.title(), \n",
    "                 text='Depth',\n",
    "                 title=f'{y.title()} vs {x.title()}',\n",
    "                theme=theme, colorscale=colorscale)\n",
    "        ## if you are using Google Colab, comment out the above line of code and uncomment the line below\n",
    "        #fig = px.scatter(df, x=x, y=y, title=f'{y.title()} vs {x.title()}')\n",
    "        #fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b546321",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define input features and target variable\n",
    "X = df[['Depth', 'Log_ILD', 'NPHI','RHOB', 'vshale', 'PHIeff', 'swirr', 'Facies_code']]\n",
    "y = df['PERM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7be9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbf0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define dictionary of models and their hyperparameters\n",
    "models = {\n",
    "    'svm': {\n",
    "        'model': make_pipeline(StandardScaler(), SVR()),\n",
    "        'params': {\n",
    "            'svr__kernel': ['linear', 'rbf', 'poly'],\n",
    "            'svr__C': [0.1, 1, 10],\n",
    "            'svr__gamma': ['scale', 'auto']\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [10, 20, 30]\n",
    "        }\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': [5, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'neural_network': {\n",
    "        'model': MLPRegressor(),\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': [(10,), (20,), (30,)],\n",
    "            'activation': ['relu', 'tanh', 'logistic']\n",
    "        }\n",
    "    },\n",
    "    'gradient_boosting': {\n",
    "        'model': GradientBoostingRegressor(),\n",
    "        'params': {\n",
    "            'learning_rate': [0.05, 0.1, 0.2],\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a8f48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "# Loop over each model and perform grid search with cross-validation to find best hyperparameters \n",
    "## scoring='neg_mean_squared_error'\n",
    "for model_name, model in models.items():\n",
    "    clf = GridSearchCV(model['model'], model['params'], cv=5, n_jobs=-1, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_params = clf.best_params_\n",
    "    \n",
    "    # Evaluate best model on test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = clf.score(X_test, y_test)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': best_params,\n",
    "        'RMSE': rmse,\n",
    "        'R-squared': r2\n",
    "    })\n",
    "    # Save the best model for each method\n",
    "    joblib.dump(clf.best_estimator_, f\"models/{model_name}_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae87c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_df = pd.DataFrame(scores, columns=['model', 'best_params', 'best_score', 'RMSE', 'R-squared'])\n",
    "best_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('data/best_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models from the model folder\n",
    "model_rf = joblib.load('models/random_forest_best_model.pkl')\n",
    "model_dt = joblib.load('models/decision_tree_best_model.pkl')\n",
    "model_gb = joblib.load('models/gradient_boosting_best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bccd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y values for x_test\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test, columns=['Depth', 'Log_ILD', 'NPHI', 'RHOB', 'vshale', 'PHIeff'])\n",
    "\n",
    "# Create a dataframe with x_test, y_test, and y_predict\n",
    "results_df = pd.DataFrame({'Depth': X_test_df['Depth'],\n",
    "                           'Log_ILD': X_test_df['Log_ILD'],\n",
    "                           'NPHI': X_test_df['NPHI'],\n",
    "                           'RHOB': X_test_df['RHOB'],\n",
    "                           'vshale': X_test_df['vshale'],\n",
    "                           'effective porosity': X_test_df['PHIeff'],\n",
    "                           'Actual Permeability': y_test,\n",
    "                           'rf_Permeability': y_pred_rf,\n",
    "                           'dt_Permeability': y_pred_dt,\n",
    "                           'gb_Permeability': y_pred_gb})\n",
    "\n",
    "# Print the dataframe\n",
    "results_df.to_csv('results.csv', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbc541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
